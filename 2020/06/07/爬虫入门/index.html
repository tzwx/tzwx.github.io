<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>爬虫入门 | 在名为未来的波浪里</title><meta name="description" content="爬虫入门"><meta name="keywords" content="python爬虫"><meta name="author" content="桑桑"><meta name="copyright" content="桑桑"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/hq.png"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="爬虫入门"><meta name="twitter:description" content="爬虫入门"><meta name="twitter:image" content="https://user-images.githubusercontent.com/60562661/83973442-f4d30200-a918-11ea-893f-0ec81988e88a.jpg"><meta property="og:type" content="article"><meta property="og:title" content="爬虫入门"><meta property="og:url" content="https://luoyou.art/2020/06/07/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/"><meta property="og:site_name" content="在名为未来的波浪里"><meta property="og:description" content="爬虫入门"><meta property="og:image" content="https://user-images.githubusercontent.com/60562661/83973442-f4d30200-a918-11ea-893f-0ec81988e88a.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'true'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://luoyou.art/2020/06/07/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/"><link rel="prev" title="从分类到逻辑回归" href="https://luoyou.art/2020/06/08/%E4%BB%8E%E5%88%86%E7%B1%BB%E5%88%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"><link rel="next" title="git错误与代理相关" href="https://luoyou.art/2020/06/06/git%E9%94%99%E8%AF%AF%E4%B8%8E%E4%BB%A3%E7%90%86%E7%9B%B8%E5%85%B3/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://huaqi.blue/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: {"languages":{"author":"Author: 桑桑","link":"Link: https://luoyou.art/2020/06/07/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/","source":"Source: 在名为未来的波浪里","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">在名为未来的波浪里</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-comments-o"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw fa fa-heart"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-picture-o"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> Life</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://user-images.githubusercontent.com/60562661/120350718-d0deac80-c331-11eb-9d6c-0164cfa5593b.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">80</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">73</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">25</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-comments-o"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw fa fa-heart"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-picture-o"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> Life</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#爬虫的大致流程"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">爬虫的大致流程</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#具体知识点"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">具体知识点</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#抓取url"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">抓取url</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#解析html-重点"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">解析html 重点</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#问题、解决："><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">问题、解决：</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#爬虫的大致流程"><span class="toc-number">1.</span> <span class="toc-text">爬虫的大致流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#具体知识点"><span class="toc-number">2.</span> <span class="toc-text">具体知识点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#抓取url"><span class="toc-number">2.1.</span> <span class="toc-text">抓取url</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解析html-重点"><span class="toc-number">2.2.</span> <span class="toc-text">解析html 重点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#问题、解决："><span class="toc-number">2.3.</span> <span class="toc-text">问题、解决：</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://user-images.githubusercontent.com/60562661/83973442-f4d30200-a918-11ea-893f-0ec81988e88a.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">爬虫入门</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> Created 2020-06-07<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> Updated 2020-06-07</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/python%E7%88%AC%E8%99%AB/">python爬虫</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>Word count:</span><span class="word-count">1.4k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>Reading time: 5 min</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>Post View:</span><span id="busuanzi_value_page_pv"></span><span class="post-meta__separator">|</span><i class="fa fa-comments-o post-meta__icon fa-fw" aria-hidden="true"></i><span>comments:</span><a href="/2020/06/07/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2020/06/07/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/" itemprop="commentCount"></span></a></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><p>近期出于某些原因突然对爬虫来了兴趣，于是花了几个小时研究了一下爬虫，重新捡起来了，理清了爬虫的一个流程，以前学了很久一直不是很懂，不会自己去爬需要的东西。理清楚之后很简单，很多东西一目了然。在此记录一下简单的爬虫流程。</p>
<h3 id="爬虫的大致流程"><a href="#爬虫的大致流程" class="headerlink" title="爬虫的大致流程"></a>爬虫的大致流程</h3><ul>
<li><strong>抓取到整个url的html代码</strong></li>
<li><strong>解析代码中需要的部分</strong></li>
<li><strong>数据保存</strong></li>
<li>高级爬虫（进阶）</li>
</ul>
<p>上述流程中，我自己只学了前两个部分，对我自己来说也是够用了，第三部分对于不以爬虫为工作的，我认为就不用专门去学习了，可以写入txt文件或者直接下载图片。。至于最后一部分就涉及到爬虫的框架，分布式爬虫等等，这个对于个人来说我觉得也是不必要的。</p>
<h3 id="具体知识点"><a href="#具体知识点" class="headerlink" title="具体知识点"></a>具体知识点</h3><h4 id="抓取url"><a href="#抓取url" class="headerlink" title="抓取url"></a>抓取url</h4><p>我用的是方便、简单的<code>requests</code>库，操作如下：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">'https://www.baidu.com'</span></span><br><span class="line">headers = {<span class="string">'User-Agent'</span>: <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50"</span>}</span><br><span class="line">response = requests.get(url=url, headers=headers)</span><br><span class="line">reponse.status_code <span class="comment"># 200表示正常访问</span></span><br><span class="line"><span class="comment">#抓取到的html的所有代码</span></span><br><span class="line">html_text = response.text</span><br></pre></td></tr></tbody></table></figure></div>
<p>第一步比较简单，几行代码，当然其中也有高级操作，比如代理之类的，后面在讲。</p>
<h4 id="解析html-重点"><a href="#解析html-重点" class="headerlink" title="解析html 重点"></a>解析html <strong>重点</strong></h4><p>xpath比较全的一个博客：<a href="https://www.jianshu.com/p/85a3004b5c06" target="_blank" rel="noopener">https://www.jianshu.com/p/85a3004b5c06</a></p>
<p>拿到html内容后，就要分析一下，找出自己需要的内容，html解析有<code>xpath</code>、<code>BeautifulSoup</code> 等库，由于<code>Bs4</code>我并不会（虽然学过），所以这里就用<code>xpath</code>~</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">表达式</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">nodename</td>
<td style="text-align:left">选取此节点的所有子节点</td>
</tr>
<tr>
<td style="text-align:left">/</td>
<td style="text-align:left">从当前节点选区直接子节点</td>
</tr>
<tr>
<td style="text-align:left">//</td>
<td style="text-align:left">全局查找某个节点</td>
</tr>
<tr>
<td style="text-align:left">.</td>
<td style="text-align:left">选取当前节点</td>
</tr>
<tr>
<td style="text-align:left">..</td>
<td style="text-align:left">选取当前节点的父节点</td>
</tr>
<tr>
<td style="text-align:left">@</td>
<td style="text-align:left">选取属性</td>
</tr>
<tr>
<td style="text-align:left">and</td>
<td style="text-align:left">多个属性同时匹配</td>
</tr>
</tbody>
</table>
</div>
<p>我认为会这些基本就够了，可以抓取下来任何自己想要的了，至少解析不会有问题。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lxml.etree</span><br><span class="line">parser = etree.HTMLParser(encoding=<span class="string">'utf-8'</span>) <span class="comment"># 创建解释器</span></span><br><span class="line">html = etree.parse(<span class="string">'baidu.html'</span>, parser=parser) <span class="comment"># 解析html</span></span><br><span class="line"><span class="comment"># xpath返回的是list</span></span><br><span class="line"><span class="comment"># 全局搜索id为pins的ul标签下面所有的li标签下面的a标签中的href(链接)</span></span><br><span class="line"><span class="comment"># @为精确匹配</span></span><br><span class="line">link = html.xpath(<span class="string">"//ul[@id='pins']//li/a/@href"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全局搜索class为"item-0"的li标签下面的第一个a标签中的文本 用/text()获取</span></span><br><span class="line">result = html.xpath(<span class="string">'//li[@class="item-0"]/a/text()'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># and表示同时满足多个属性</span></span><br><span class="line">result = html.xpath(<span class="string">'//li[contains(@class, "li") and @name="item"]/a/text()'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模糊匹配 全局搜索class名称包含'li'的li标签下面的第一个a标签中的文本  </span></span><br><span class="line">result = html.xpath(<span class="string">'//li[contains(@class, "li")]/a/text()'</span>)</span><br></pre></td></tr></tbody></table></figure></div>
<p>至此就解析完成，拿到了自己想要的，爬虫基本也随之结束了。</p>
<p>拿到的是一堆字符串，要下载要提取就用python的方法处理即可，关于下载图片可以用requests直接保存：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">h = open(img_name,<span class="string">'wb'</span>) <span class="comment"># img_name 为要保存的图片名称</span></span><br><span class="line">h.write(requests.get(img_src,headers=header).content) <span class="comment">#img_src为字符串</span></span><br><span class="line">h.close()</span><br></pre></td></tr></tbody></table></figure></div>
<h4 id="问题、解决："><a href="#问题、解决：" class="headerlink" title="问题、解决："></a>问题、解决：</h4><ul>
<li><p><strong>抓取url</strong></p>
<p>在抓取url时(<strong>get</strong>)，有时候非常慢，或者是下载多了ip会直接被封。有以下几个解决方案:</p>
<ul>
<li><p>爬虫时例如下载图片时，一定要有时间间隔</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure></div>
</li>
<li><p>动态获取ip：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># # @Time    : 2020/6/7 下午 8:09</span></span><br><span class="line"><span class="comment"># # @Author  : fry</span></span><br><span class="line"><span class="comment"># @FileName: ip.py</span></span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pnw</span><span class="params">()</span>:</span>  <span class="comment"># 定义一个循环的函数</span></span><br><span class="line">    headers = {</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 "</span></span><br><span class="line">                      <span class="string">"(KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1"</span>}</span><br><span class="line">    <span class="comment"># 依次遍历生成2-99</span></span><br><span class="line">    ip_address = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">100</span>):</span><br><span class="line">        url = <span class="string">"https://www.kuaidaili.com/free/inha/"</span> + str(i) + <span class="string">"/"</span>  <span class="comment"># 爬取的免费ip</span></span><br><span class="line">        response = requests.get(url, headers=headers).text  <span class="comment"># 获得网页文本数据</span></span><br><span class="line">        response_xpath = etree.HTML(response)  <span class="comment"># 转换为xpath可用结构</span></span><br><span class="line">        ips = response_xpath.xpath(<span class="string">'//*[@id="list"]/table/tbody/tr/td[1]/text()'</span>)  <span class="comment"># ip的信息</span></span><br><span class="line">        dks = response_xpath.xpath(<span class="string">'//*[@id="list"]/table/tbody/tr/td[2]/text()'</span>)  <span class="comment"># 端口的信息</span></span><br><span class="line">        https = response_xpath.xpath(<span class="string">'//*[@id="list"]/table/tbody/tr[2]/td[4]/text()'</span>)  <span class="comment"># http信息</span></span><br><span class="line">        <span class="keyword">for</span> ip, dk, http <span class="keyword">in</span> zip(ips, dks, https):</span><br><span class="line">            proxy = <span class="string">"http://"</span> + ip + <span class="string">":"</span> + dk  <span class="comment"># 拼接ip</span></span><br><span class="line">            proxies = {<span class="string">"http"</span>: proxy}</span><br><span class="line">            ip_address.append(proxies)</span><br><span class="line">    <span class="keyword">return</span> ip_address</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    ips = pnw()</span><br><span class="line">    print(ips)</span><br></pre></td></tr></tbody></table></figure></div>
<p>以上代码可以获取ip，使用时:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip = pnw()</span><br><span class="line">pic_page = requests.get(url=url_pic, headers=header,proxies=ip[<span class="number">0</span>]) <span class="comment">#使用ip代理</span></span><br></pre></td></tr></tbody></table></figure></div>
</li>
</ul>
</li>
</ul>
<p>  基本如此，掌握之后可以随心所欲爬取自己所需。</p>
<hr>
<ul>
<li><p>如果想要爬一个网站所有的东西，<strong>需要自己去分析一下url规律</strong>，比如哪个标签里面有所有的链接等等</p>
</li>
<li><p>关于反爬机制，用好代理</p>
<p><strong>最后，关于爬虫的合法性：</strong></p>
<p><code>url</code>拼接上<a href="https://www.taobao.com/robots.txt" target="_blank" rel="noopener">/robots.txt</a>  可以看到网站的爬虫协议：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yaml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">User-agent:</span>  <span class="string">Baiduspider</span> <span class="comment"># 允许百度爬虫引擎</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/article</span> <span class="comment"># 允许访问/article.htm，/article/12345.com</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/oshtml</span>      </span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/wenzhang</span></span><br><span class="line"><span class="attr">Disallow:</span>  <span class="string">/product/</span> <span class="comment"># 禁止访问/product/12345.com</span></span><br><span class="line"><span class="attr">Disallow:</span>  <span class="string">/</span>         <span class="comment"># 禁止了访问除Allow规定页面的其他所有页面</span></span><br><span class="line"></span><br><span class="line"><span class="attr">User-Agent:</span>  <span class="string">Googlebot</span>  <span class="comment"># 谷歌爬虫引擎</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/article</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/oshtml</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/product</span> <span class="comment"># 允许访问/product.htm，/product/12345.com</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/spu</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/dianpu</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/wenzhang</span></span><br><span class="line"><span class="attr">Allow:</span>  <span class="string">/oversea</span></span><br><span class="line"><span class="attr">Disallow:</span>  <span class="string">/</span></span><br></pre></td></tr></tbody></table></figure></div>
<p>但是这只是网站的协议，具体的：</p>
<p><strong>从目前的情况来看，如果抓取的数据属于个人使用或科研范畴，基本不存在问题; 而如果数据属于商业盈利范畴，就要就事而论，有可能属于违法行为，也有可能不违法。</strong></p>
</li>
</ul>
<hr>
<p>  最近写了一个爬虫可以抓取某网站<strong>所有</strong>的图片(<strong>增加科研兴趣</strong>，现有网络的代码只能抓取某几页)，具体代码就不放出来了。需要可以通过关于我z红的<code>email</code>  、<code>微信</code>联系我。</p>
</body></html></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">桑桑</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://luoyou.art/2020/06/07/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/">https://luoyou.art/2020/06/07/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python%E7%88%AC%E8%99%AB/">python爬虫    </a></div><div class="post_share"><div class="social-share" data-image="https://user-images.githubusercontent.com/60562661/83973442-f4d30200-a918-11ea-893f-0ec81988e88a.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/06/08/%E4%BB%8E%E5%88%86%E7%B1%BB%E5%88%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"><img class="prev_cover lazyload" data-src="https://user-images.githubusercontent.com/60562661/83933911-3a8baf80-a7df-11ea-8e9e-253c0be24056.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>从分类到逻辑回归</span></div></a></div><div class="next-post pull_right"><a href="/2020/06/06/git%E9%94%99%E8%AF%AF%E4%B8%8E%E4%BB%A3%E7%90%86%E7%9B%B8%E5%85%B3/"><img class="next_cover lazyload" data-src="https://user-images.githubusercontent.com/60562661/73609075-07ed6280-4605-11ea-9971-35fe0663a9e0.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>git错误与代理相关</span></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> Comment</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = true == true ? true : false;
var verify = false == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'s7Rhlvw79F57TPCoI7ybwiKJ-gzGzoHsz',
  appKey:'oSBw1EY1n1eGhYK9f5jsdual',
  placeholder:'留下你的足迹...',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10',
  lang:'en',
  recordIP: true
});</script></div></div></main><footer id="footer" style="background-image: url(https://user-images.githubusercontent.com/60562661/83973442-f4d30200-a918-11ea-893f-0ec81988e88a.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By 桑桑</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="Scroll to comment"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script id="canvas_nest" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script src="https://cdn.jsdelivr.net/npm/activate-power-mode/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true; 
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>