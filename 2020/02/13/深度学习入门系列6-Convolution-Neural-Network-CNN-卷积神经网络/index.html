<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>深度学习入门系列6: Convolution Neural Network(CNN)卷积神经网络 | 子规声里驻年光</title><meta name="description" content="深度学习入门系列6: Convolution Neural Network(CNN)卷积神经网络"><meta name="keywords" content="DeepLearning"><meta name="author" content="桦七"><meta name="copyright" content="桦七"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/hq.png"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="深度学习入门系列6: Convolution Neural Network(CNN)卷积神经网络"><meta name="twitter:description" content="深度学习入门系列6: Convolution Neural Network(CNN)卷积神经网络"><meta name="twitter:image" content="https://user-images.githubusercontent.com/60562661/74444161-66d99400-4eaf-11ea-9065-e4dce2e33e56.png"><meta property="og:type" content="article"><meta property="og:title" content="深度学习入门系列6: Convolution Neural Network(CNN)卷积神经网络"><meta property="og:url" content="http://yoursite.com/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><meta property="og:site_name" content="子规声里驻年光"><meta property="og:description" content="深度学习入门系列6: Convolution Neural Network(CNN)卷积神经网络"><meta property="og:image" content="https://user-images.githubusercontent.com/60562661/74444161-66d99400-4eaf-11ea-9065-e4dce2e33e56.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://yoursite.com/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><link rel="prev" title="深度学习入门系列7: Tips For DeepLearning_1 全程高能!" href="http://yoursite.com/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%977-Tips-For-DeepLearning-%E5%85%A8%E7%A8%8B%E9%AB%98%E8%83%BD/"><link rel="next" title="深度学习入门系列5: 反向传播BP算法" href="http://yoursite.com/2020/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%974-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADBP%E7%AE%97%E6%B3%95/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://huaqi.blue/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: {"languages":{"author":"Author: 桦七","link":"Link: http://yoursite.com/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","source":"Source: 子规声里驻年光","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">子规声里驻年光</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-picture-o"></i><span> Gallery</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/tx2.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">19</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">13</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">5</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-picture-o"></i><span> Gallery</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#CNN的提出"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">CNN的提出</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#CNN一般架构"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">CNN一般架构</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Convolution计算流程"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">Convolution计算流程</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#单通道卷积计算"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">单通道卷积计算</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#多通道卷积计算"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text">多通道卷积计算</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Convolution-amp-Neural-Network"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">Convolution &amp; Neural Network</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#大量参数的减少"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">大量参数的减少</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#参数共享"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text">参数共享</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#池化-Max-pooling"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">池化 Max pooling</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Conclusion"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">Conclusion</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CNN的提出"><span class="toc-number">1.</span> <span class="toc-text">CNN的提出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CNN一般架构"><span class="toc-number">2.</span> <span class="toc-text">CNN一般架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convolution计算流程"><span class="toc-number">3.</span> <span class="toc-text">Convolution计算流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#单通道卷积计算"><span class="toc-number">3.1.</span> <span class="toc-text">单通道卷积计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多通道卷积计算"><span class="toc-number">3.2.</span> <span class="toc-text">多通道卷积计算</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convolution-amp-Neural-Network"><span class="toc-number">4.</span> <span class="toc-text">Convolution &amp; Neural Network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#大量参数的减少"><span class="toc-number">4.1.</span> <span class="toc-text">大量参数的减少</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参数共享"><span class="toc-number">4.2.</span> <span class="toc-text">参数共享</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#池化-Max-pooling"><span class="toc-number">5.</span> <span class="toc-text">池化 Max pooling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">6.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://user-images.githubusercontent.com/60562661/74444161-66d99400-4eaf-11ea-9065-e4dce2e33e56.png)"><div id="post-info"><div id="post-title"><div class="posttitle">深度学习入门系列6: Convolution Neural Network(CNN)卷积神经网络</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> Created 2020-02-13<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> Updated 2020-02-13</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>Word count:</span><span class="word-count">1.7k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>Reading time: 5 min</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>Post View:</span><span id="busuanzi_value_page_pv"></span><span class="post-meta__separator">|</span><i class="fa fa-comments-o post-meta__icon fa-fw" aria-hidden="true"></i><span>comments:</span><a href="/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="commentCount"></span></a></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><h2 id="CNN的提出"><a href="#CNN的提出" class="headerlink" title="CNN的提出"></a>CNN的提出</h2><p><strong>其一，</strong>之前所提到的线性回归、比较简单逻辑回归都是全连接层<strong>(Full-Connected)</strong> ,那么在图像处理领域输入数据都是图像，现实中一张很小的图 <strong>100 * 100</strong> ，分辨率已经很低了，然是依然有<strong>30000 维数据</strong>，(这里默认图象是彩色图三通道的)，然后后面再堆几层网络，参数量实在是巨大，这是全连接网络的缺陷；</p>
<p><strong>其二，</strong>基于现实的观察有以下基点：</p>
<ul>
<li><p>假设CNN中每一个神经元都是用来识别某一个<strong>pattern</strong>[例如：鼻子，嘴，手臂] (实际上大概也是这样工作的)</p>
</li>
<li><p>人们在辨识一些小的部分比如鸟喙时，并不需要遍历一张图的所有信息，而是看到图片的一小部分就可以捕捉到需要的信息；</p>
</li>
<li><p>同一个部分(鸟喙)在图像中可能会出现在不同的位置，因此CNN的神经元以相同的参数就可以发现不同位置的鸟喙而不用重新学习参数</p>
</li>
<li><p>图像进行下采样，并不会影响我们对图片的观察(不包括比较极端的)；而图像较小的时候像素比较少此时也会减少参数</p>
</li>
</ul>
<p>基于以上，CNN卷积神经网络就正式提出了，并且在计算机视觉领域(影像处理)非常有效，几乎所有的任务，第一步都是要用卷积神经网络来提取特征。</p>
<h2 id="CNN一般架构"><a href="#CNN一般架构" class="headerlink" title="CNN一般架构"></a>CNN一般架构</h2><p>卷积神经网络一般是输入图像，然后经过 （卷积层、池化层）这两个一直重复，然后输出的像素拉平(flatten操作将当前值转变为一维向量)，连接上全连结网络输出，如下图：</p>
<a href="https://user-images.githubusercontent.com/60562661/74443982-1e21db00-4eaf-11ea-973c-7b46e241d959.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="1581600351984" class="fancybox"><img alt="1581600351984" style="zoom: 67%;" data-src="https://user-images.githubusercontent.com/60562661/74443982-1e21db00-4eaf-11ea-973c-7b46e241d959.png" class="lazyload" title="1581600351984"></a>

<h2 id="Convolution计算流程"><a href="#Convolution计算流程" class="headerlink" title="Convolution计算流程"></a>Convolution计算流程</h2><p><strong>首先，CNN中要训练的参数就是卷积核的每个像素的数值</strong></p>
<h3 id="单通道卷积计算"><a href="#单通道卷积计算" class="headerlink" title="单通道卷积计算"></a>单通道卷积计算</h3><a href="https://user-images.githubusercontent.com/60562661/74443985-1f530800-4eaf-11ea-8059-661371e1f691.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom: 67%;" data-src="https://user-images.githubusercontent.com/60562661/74443985-1f530800-4eaf-11ea-8059-661371e1f691.png" class="lazyload"></a>

<p>如上图，用filter1在图像6<em>6图像上滑动，从左上角开始，步长为1，在每个窗格对应位置相乘然后加起来输出一个新的值，此时就会形成一个新的4 *</em> 4的 img ，称为特征图*<em>Feature Map *</em>。</p>
<p>此时有一个卷积核，就输出一张特征图，两个卷积核就输出两张特征图，以此类推。</p>
<h3 id="多通道卷积计算"><a href="#多通道卷积计算" class="headerlink" title="多通道卷积计算"></a>多通道卷积计算</h3><a href="https://user-images.githubusercontent.com/60562661/74443978-1c581780-4eaf-11ea-923b-a7975171f4d7.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="1581598043317" class="fancybox"><img alt="1581598043317" style="zoom: 67%;" data-src="https://user-images.githubusercontent.com/60562661/74443978-1c581780-4eaf-11ea-923b-a7975171f4d7.png" class="lazyload" title="1581598043317"></a>

<p>如果输入的图像是三通道的，那么每个卷积核对应的也是三通道的，注意此时计算可能是：</p>
<p>卷积核的第一个通道与图像红色通道进行卷积运算，卷积核的第二个通道与图像绿色通道进行卷积运算，卷积核的第三个通道与图像蓝色通道进行卷积运算，然后 卷积核三个通道输出的img对应位置相加，形成一个新的1个通道的img，就是这个卷积核所输出的 <strong>Feature Map</strong>  。这里注意的是： 对于多通道图像，<code>一个卷积核进行卷积运算后所输出的依然是一个 feature map，而不是9个(3*3).</code></p>
<h2 id="Convolution-amp-Neural-Network"><a href="#Convolution-amp-Neural-Network" class="headerlink" title="Convolution & Neural Network"></a>Convolution & Neural Network</h2><p>以上讲了卷积的运算方式，那么卷积与神经网络，与全连接网络有什么关系呢？</p>
<p><strong>卷积实际上就是全连接网络(去掉一些weight) !</strong></p>
<a href="https://user-images.githubusercontent.com/60562661/74443980-1d894480-4eaf-11ea-81f5-dde23c1db352.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="1581598946132" class="fancybox"><img alt="1581598946132" style="zoom: 67%;" data-src="https://user-images.githubusercontent.com/60562661/74443980-1d894480-4eaf-11ea-81f5-dde23c1db352.png" class="lazyload" title="1581598946132"></a>

<p>分析一下这张图，</p>
<ul>
<li><p>首先右边蓝色的 1 2 3 4 ···一直到16，表示的是将左边6*6的图像拉平（这里没有画完），蓝色的框里的数字是每个像素的值；</p>
</li>
<li><p>然后上面是个3*3的卷积核，每个像素用不同颜色的⚪圈了起来；</p>
</li>
<li><p>然后上图右边部分橙色的 3，-1 就是 卷积核与图像滑动过的区域做的卷积计算得到的数值，将卷积核卷积后的4*4的img也拉平，就得到了右边的 3 ，-1  （这里用3和-1举例子所以没有画完）</p>
</li>
</ul>
<h3 id="大量参数的减少"><a href="#大量参数的减少" class="headerlink" title="大量参数的减少"></a>大量参数的减少</h3><p>卷积之后得到的图像的每个像素也就是右边的3，-1 等，可以看作是一个神经元，其中 卷积核做图像左上角的时候，计算刚好是与原来的6<em>6图像的 编号为 1 2 3 7 8 9 13 14 15 的像素进行的，因此“*</em>3**”这个神经元就连接到了编号为 1 2 3 7 8 9 13 14 15 的像素，-1是同样的道理。这时候，如果计算参数量，就是 16 * 9 = 144 个参数，而此时如果用全连接层的话，就是 36 * 16 = 576 个参数，已经少了很多了</p>
<h3 id="参数共享"><a href="#参数共享" class="headerlink" title="参数共享"></a>参数共享</h3><p>上图中右边部分的神经元，并不是说所有的参数都要计算。一个卷积核中同一个像素滑动过的值他们之间的权重都是强迫相等的。举个例子，卷积核中的第一个像素(深红色圆圈)，与6<em>6的图像在左上角计算卷积时对应的编号为1的像素，卷积核向右滑动一次后，该像素(深红色圆圈)对应的是编号为2的像素，因此 上图右边部分 1 号像素和 右边的神经元3 ， 2号像素与右边的神经元-1之间连接都用的是深红色，这两条线的参数就是相等的。所以同理，上图右边部分连线中颜色相同的权值都是共享的。(*</em>Share Weights**) 此来再来计算一下参数量，就只有9个了。</p>
<p>这其实也不难理解，一开始文章就提到，卷积神经网络的参数就是卷积核的像素值，这里是3*3的卷积核9个像素，所以也就只有9个参数了。到这里已经是全连接网络的 1/64 了，也就是减少了64倍的参数，这在 上百万参数是减少的就更明显了！</p>
<p><strong>到这里，已经理解了卷积神经网络的计算方式以及如何减少参数</strong></p>
<h2 id="池化-Max-pooling"><a href="#池化-Max-pooling" class="headerlink" title="池化 Max pooling"></a>池化 Max pooling</h2><p><a href="https://user-images.githubusercontent.com/60562661/74443974-1a8e5400-4eaf-11ea-91d0-250625a1d4ad.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt data-src="https://user-images.githubusercontent.com/60562661/74443974-1a8e5400-4eaf-11ea-91d0-250625a1d4ad.jpg" class="lazyload" title></a></p>
<p>在卷积输出的特征图基础上，以2*2为单位，每个红色框里选出最的值组成一个新的img，这就是最大池化；</p>
<p>平均池化就是一个红色框里所有的像素值取平均。 </p>
<p>经过池化，图像尺寸变为 2*2 </p>
<p><strong>池化层采用最大池化方式，那么怎么求微分呢？不可导就不能梯度下降，这个下一篇文章会说。</strong></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>以上就是CNN，卷积神经网络，工作方式可以理解为某一层的神经元识别一个 pattern ，然后全连接层组合这些个 pattern 最后提取出高质量的特征。 这个可以自己求证一下。大概可以这么解释。</p>
</body></html></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">桦七</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">http://yoursite.com/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning    </a></div><div class="post_share"><div class="social-share" data-image="https://user-images.githubusercontent.com/60562661/74444161-66d99400-4eaf-11ea-9065-e4dce2e33e56.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%977-Tips-For-DeepLearning-%E5%85%A8%E7%A8%8B%E9%AB%98%E8%83%BD/"><img class="prev_cover lazyload" data-src="https://user-images.githubusercontent.com/60562661/74454032-41a05200-4ebe-11ea-9a0e-663903d2f49b.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>深度学习入门系列7: Tips For DeepLearning_1 全程高能!</span></div></a></div><div class="next-post pull_right"><a href="/2020/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%974-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADBP%E7%AE%97%E6%B3%95/"><img class="next_cover lazyload" data-src="https://user-images.githubusercontent.com/60562661/74358980-5b2d9500-4dfd-11ea-9535-3f70a442afcf.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>深度学习入门系列5: 反向传播BP算法</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/02/14/深度学习入门系列8-Tips-For-DeepLearning-2-全程高能/" title="深度学习入门系列8: Tips For DeepLearning_2 全程高能!"><img class="relatedPosts_cover lazyload"data-src="https://user-images.githubusercontent.com/60562661/74508069-2161a900-4f39-11ea-86b5-056ac59fd796.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-14</div><div class="relatedPosts_title">深度学习入门系列8: Tips For DeepLearning_2 全程高能!</div></div></a></div><div class="relatedPosts_item"><a href="/2020/02/11/深度学习入门系列-逻辑回归/" title="深度学习入门系列4: Logistic Regression"><img class="relatedPosts_cover lazyload"data-src="https://user-images.githubusercontent.com/60562661/74258373-2ce28380-4d31-11ea-9573-5ed9e4e63fd1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-11</div><div class="relatedPosts_title">深度学习入门系列4: Logistic Regression</div></div></a></div><div class="relatedPosts_item"><a href="/2020/02/11/深度学习入门系列-深度学习的误差来自哪里/" title="深度学习入门系列3: 模型的误差来源及其改进"><img class="relatedPosts_cover lazyload"data-src="https://user-images.githubusercontent.com/60562661/74254491-7a5bf200-4d2b-11ea-841c-bb6c1fe2d0c4.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-11</div><div class="relatedPosts_title">深度学习入门系列3: 模型的误差来源及其改进</div></div></a></div><div class="relatedPosts_item"><a href="/2020/02/12/深度学习入门系列4-反向传播BP算法/" title="深度学习入门系列5: 反向传播BP算法"><img class="relatedPosts_cover lazyload"data-src="https://user-images.githubusercontent.com/60562661/74358980-5b2d9500-4dfd-11ea-9535-3f70a442afcf.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-12</div><div class="relatedPosts_title">深度学习入门系列5: 反向传播BP算法</div></div></a></div><div class="relatedPosts_item"><a href="/2020/02/10/深度学习入门系列一-梯度下降法/" title="深度学习入门系列1: 梯度下降法①"><img class="relatedPosts_cover lazyload"data-src="https://user-images.githubusercontent.com/60562661/74164708-1b30ab80-4c5f-11ea-921d-071649d05842.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-10</div><div class="relatedPosts_title">深度学习入门系列1: 梯度下降法①</div></div></a></div><div class="relatedPosts_item"><a href="/2020/02/13/深度学习入门系列7-Tips-For-DeepLearning-全程高能/" title="深度学习入门系列7: Tips For DeepLearning_1 全程高能!"><img class="relatedPosts_cover lazyload"data-src="https://user-images.githubusercontent.com/60562661/74454032-41a05200-4ebe-11ea-9a0e-663903d2f49b.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-13</div><div class="relatedPosts_title">深度学习入门系列7: Tips For DeepLearning_1 全程高能!</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> Comment</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = false == true ? true : false;
var verify = false == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'s7Rhlvw79F57TPCoI7ybwiKJ-gzGzoHsz',
  appKey:'oSBw1EY1n1eGhYK9f5jsdual',
  placeholder:'Please leave your footprints',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10',
  lang:'en',
  recordIP: true
});</script></div></div></main><footer id="footer" style="background-image: url(https://user-images.githubusercontent.com/60562661/74444161-66d99400-4eaf-11ea-9065-e4dce2e33e56.png)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By 桦七</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="Scroll to comment"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script id="canvas_nest" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>